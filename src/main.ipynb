{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e1730f5",
   "metadata": {},
   "source": [
    "# Fine Tuning for Summarisation Task\n",
    "## Introduction\n",
    "As stated, trying to perform the task of abstractive summarisation through fine tuning a T5 model. As the T5 model has both encoder and the decoder pre-trained, fine-tuning it on dataset should be great start for the task.\n",
    "\n",
    "While T5 is pre-trained for summarisation task on normal CNN/Daily Mail dataset already, this serves as a demonstration to show how to do it for any domain specific summarisation if needed. \n",
    "\n",
    "We are also fine-tuning using Low-Rank Adaptation (LoRA), therefore only small number of parameters have to be fine-tuned for the task, that will augment the baseline model. We will compare then compare its performance in summarisation against the standard non fine-tuned instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b5e3364d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import section\n",
    "from bert_score import score\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from transformers import T5ForConditionalGeneration\n",
    "from transformers.trainer import Trainer\n",
    "from transformers.training_args import TrainingArguments\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "import torch\n",
    "\n",
    "from typing import cast\n",
    "\n",
    "from utils import preprocess_function, get_model_name, get_tokenizer, get_data_collator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d3edcc",
   "metadata": {},
   "source": [
    "## Section 1: Preparing the Dataset\n",
    "The CNN/Daily Mail Dataset of News Articles and their highlights have been hosted as a [huggingface dataset](https://huggingface.co/datasets/abisee/cnn_dailymail) and therefore can be downloaded through the `datasets` library of huggingface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fe13983",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n",
    "dataset = cast(DatasetDict, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230acacb",
   "metadata": {},
   "source": [
    "### 1.1. Inspect the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "477dbd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article:\n",
      "LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won't cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappoi\n",
      "\n",
      "Summary:\n",
      "Harry Potter star Daniel Radcliffe gets £20M fortune as he turns 18 Monday .\n",
      "Young actor says he has no plans to fritter his cash away .\n",
      "Radcliffe's earnings from first five Potter films have been held in trust fund .\n"
     ]
    }
   ],
   "source": [
    "sample = dataset['train'][0]\n",
    "\n",
    "print(\"Article:\")\n",
    "print(sample['article'][:300])\n",
    "print(\"\")\n",
    "print(\"Summary:\")\n",
    "print(sample['highlights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d75b005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 287113\n",
      "Number of validation samples: 13368\n",
      "Number of test samples: 11490\n"
     ]
    }
   ],
   "source": [
    "# Check the number of samples present\n",
    "print(f\"Number of training samples: {len(dataset['train'])}\")\n",
    "print(f\"Number of validation samples: {len(dataset['validation'])}\")\n",
    "print(f\"Number of test samples: {len(dataset['test'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1fdee4",
   "metadata": {},
   "source": [
    "### 1.2. Split dataset into tokens ready for consumption by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c7255f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceeff2ace77d4f9989f7774d321aaa35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/287113 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d7fcfe0561e4e6fa0f3f40b0f28ce8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/13368 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54fefa8c23c846e2802f013665e9ea41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/11490 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(preprocess_function, batched=True, num_proc=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4878b029",
   "metadata": {},
   "source": [
    "## Section 2: Creating the model and the LoRA Config\n",
    "The hugging face interface makes it very easy to perform fine-tuning using LoRA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65a4a4c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1445bdb6d0cc41bda08ff101dc987916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80142236f783429ab4ef32b3d3f0553d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31e3667b34ce47d6b15407b583715adb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Conditional Generation is needed over raw hidden encoder decoder stats from T5Model for this task.\n",
    "# This comes with the needed vocabulary logits for generating the summary tokens.\n",
    "model = T5ForConditionalGeneration.from_pretrained(get_model_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17583f5",
   "metadata": {},
   "source": [
    "We create the following LoRA config\n",
    "1. Use rank 8 to reduce the number of parameters.\n",
    "2. Alpha influences how much LoRA matrix contributes to the final output.\n",
    "3. We target the Query and Values part of the attention module in the model for Adaptation, as they are the most impactful.\n",
    "4. Adding dropout of 0.05 for better regularisation.\n",
    "5. Biases are not adapted as of now.\n",
    "6. Since it generates a summary from article, it is a sequence to sequence task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11b22d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA Config\n",
    "lora_config = LoraConfig(r=8, lora_alpha=16, target_modules=[\"q\", \"v\"],\n",
    "                         lora_dropout=0.05, bias=\"none\", task_type=TaskType.SEQ_2_SEQ_LM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3dd920",
   "metadata": {},
   "source": [
    "We then add LoRA adapter to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da2d227e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 294,912 || all params: 60,801,536 || trainable%: 0.4850\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# Show how many parameters we train for indicating efficiency.\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d71957f",
   "metadata": {},
   "source": [
    "## Section 3: Creating a Trainer\n",
    "Now that we have obtained the appropriate tokens for the model to consume from the dataset and created a LoRA wrapped model instance for fine-tuning, we will create the trainer instance to actually train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5581af14",
   "metadata": {},
   "source": [
    "Creating an instance of the TrainingArguments to be supplied to the Trainer.\n",
    "1. Saving the weights to the results folder.\n",
    "2. Evaluating the performance every 500 steps and logging progress every 100 steps.\n",
    "3. On a training and evaluation batch size of 16.\n",
    "4. With a very small learning rate of 1e-5 as it is a fine tuning task.\n",
    "5. Warm up starts with a lower learning rate and then gradually increases to our set learning rate to ensure stability.\n",
    "6. Save the weights every 1000 steps and only retain the 2 most recent checkpoints.\n",
    "7. Use mixed precision for faster training.\n",
    "8. Save the logs to the logs folder and no remote report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e4f4330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust these according to your hardware constraints and performance requirements.\n",
    "TOTAL_EPOCHS=1\n",
    "TRAIN_BATCH=64\n",
    "EVAL_BATCH=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04f7fbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TrainingArguments instance to give the trainer its configuration.\n",
    "training_args = TrainingArguments(output_dir='./results', eval_steps=500, logging_steps=100, \n",
    "                                  per_device_train_batch_size=TRAIN_BATCH, per_device_eval_batch_size=EVAL_BATCH, \n",
    "                                  num_train_epochs=TOTAL_EPOCHS, learning_rate=1e-5, \n",
    "                                  warmup_steps=200, save_steps=1000, save_total_limit=2, fp16=True,\n",
    "                                  logging_dir='./logs', report_to='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba2cc4d",
   "metadata": {},
   "source": [
    "### 3.1. Create an instance of Trainer for training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e358264",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model=model, args=training_args, train_dataset=tokenized_dataset['train'], \n",
    "                  eval_dataset=tokenized_dataset['validation'], data_collator=get_data_collator(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97b5e3e",
   "metadata": {},
   "source": [
    "### 3.2. Run the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccae1e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4487' max='4487' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4487/4487 34:41, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.207700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.197200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.200900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.161500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.162500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.151100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.148400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.140300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>2.135300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.134600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>2.132600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.126600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.125600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>2.134300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>2.127600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>2.129800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>2.121200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.121600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>2.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>2.108200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>2.118600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>2.107400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>2.111400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>2.108200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>2.105900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>2.081400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>2.105900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.097500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>2.098700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>2.094200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>2.121800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>2.096000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>2.098200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>2.110900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>2.101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>2.113700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>2.106200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.099900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>2.096800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>2.107300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>2.110700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>2.100600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4487, training_loss=2.123746235598587, metrics={'train_runtime': 2082.2125, 'train_samples_per_second': 137.888, 'train_steps_per_second': 2.155, 'total_flos': 3.911850631417037e+16, 'train_loss': 2.123746235598587, 'epoch': 1.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b555a90b",
   "metadata": {},
   "source": [
    "### 3.3. Save the model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0780935",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"t5-small-lora-ft\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ec79a9",
   "metadata": {},
   "source": [
    "## Section 4: Generate a summary from a real article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e29a5c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch our fine-tuned model to eval mode, to prevent calculation of gradients.\n",
    "model.eval()\n",
    "tokenizer = get_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d572933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CNN)The Palestinian Authority officially became the 123rd member of the International Criminal Court on Wednesday, a step that gives the court jurisdiction over alleged crimes in Palestinian territories. The formal accession was marked with a ceremony at The Hague, in the Netherlands, where the court is based. The Palestinians signed the ICC's founding Rome Statute in January, when they also accepted its jurisdiction over alleged crimes committed \"in the occupied Palestinian territory, including East Jerusalem, since June 13, 2014.\" Later that month, the ICC opened a preliminary examination into the situation in Palestinian territories, paving the way for possible war crimes investigations against Israelis. As members of the court, Palestinians may be subject to counter-charges as well. Israel and the United States, neither of which is an ICC member, opposed the Palestinians' efforts to join the body. But Palestinian Foreign Minister Riad al-Malki, speaking at Wednesday's ceremony, said it was a move toward greater justice. \"As Palestine formally becomes a State Party to the Rome Statute today, the world is also a step closer to ending a long era of impunity and injustice,\" he said, according to an ICC news release. \"Indeed, today brings us closer to our shared goals of justice and peace.\" Judge Kuniko Ozaki, a vice president of the ICC, said acceding to the treaty was just the first step for the Palestinians. \"As the Rome Statute today enters into force for the State of Palestine, Palestine acquires all the rights as well as responsibilities that come with being a State Party to the Statute. These are substantive commitments, which cannot be taken lightly,\" she said. Rights group Human Rights Watch welcomed the development. \"Governments seeking to penalize Palestine for joining the ICC should immediately end their pressure, and countries that support universal acceptance of the court's treaty should speak out to welcome its membership,\" said Balkees Jarrah, international justice counsel for the group. \"What's objectionable is the attempts to undermine international justice, not Palestine's decision to join a treaty to which over 100 countries around the world are members.\" In January, when the preliminary ICC examination was opened, Israeli Prime Minister Benjamin Netanyahu described it as an outrage, saying the court was overstepping its boundaries. The United States also said it \"strongly\" disagreed with the court's decision. \"As we have said repeatedly, we do not believe that Palestine is a state and therefore we do not believe that it is eligible to join the ICC,\" the State Department said in a statement. It urged the warring sides to resolve their differences through direct negotiations. \"We will continue to oppose actions against Israel at the ICC as counterproductive to the cause of peace,\" it said. But the ICC begs to differ with the definition of a state for its purposes and refers to the territories as \"Palestine.\" While a preliminary examination is not a formal investigation, it allows the court to review evidence and determine whether to investigate suspects on both sides. Prosecutor Fatou Bensouda said her office would \"conduct its analysis in full independence and impartiality.\" The war between Israel and Hamas militants in Gaza last summer left more than 2,000 people dead. The inquiry will include alleged war crimes committed since June. The International Criminal Court was set up in 2002 to prosecute genocide, crimes against humanity and war crimes. CNN's Vasco Cotovio, Kareem Khadder and Faith Karimi contributed to this report.\n"
     ]
    }
   ],
   "source": [
    "real_article = dataset[\"test\"][0][\"article\"]\n",
    "print(real_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc0e0d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Palestinian Authority officially became the 123rd member of the International Criminal Court. The formal accession was marked with a ceremony at The Hague, in the Netherlands. Israel and the United States opposed the Palestinians' efforts to join the body.\n"
     ]
    }
   ],
   "source": [
    "article_text = \"summarize: \" + real_article\n",
    "inputs = tokenizer(article_text, return_tensors=\"pt\",\n",
    "                   truncation=True, max_length=512)\n",
    "inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
    "\n",
    "# Generate summary\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(**inputs, max_length=128, num_beams=4)\n",
    "\n",
    "summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Print the generated summary\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7d46ef",
   "metadata": {},
   "source": [
    "## Section 5: Compare with Baseline on summarisation performance\n",
    "BERTScore will be used as it compares the semantic meaning over literal n-gram overlap (as in the case of ROUGE) and therefore is better suited to measure performance of an abstractive summarisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3bdad029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded control model!\n"
     ]
    }
   ],
   "source": [
    "# Base model instance to compare performance against\n",
    "base_model = T5ForConditionalGeneration.from_pretrained(\"t5-small\").to(\"cuda\")\n",
    "\n",
    "# 200 articles for performance evaluation\n",
    "test_set = dataset['test'].select(range(200))\n",
    "test_set = cast(Dataset, test_set)\n",
    "\n",
    "base_model.eval()\n",
    "model.eval()\n",
    "print(\"Loaded control model!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "63a0ac3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the summaries from both model instances\n",
    "baseline_summaries = []\n",
    "finetuned_summaries = []\n",
    "\n",
    "for item in test_set:\n",
    "    input_text = \"summarize: \" + item[\"article\"]\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\",\n",
    "                       truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        output1 = base_model.generate(**inputs, max_length=128)\n",
    "        output2 = model.generate(**inputs, max_length=128)\n",
    "    summary1 = tokenizer.decode(output1[0], skip_special_tokens=True)\n",
    "    summary2 = tokenizer.decode(output2[0], skip_special_tokens=True)\n",
    "    baseline_summaries.append(summary1)\n",
    "    finetuned_summaries.append(summary2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "29134b90-b54a-4671-bc15-566098f1eff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "823402c9fb344254b64047325541acde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8b51787afc34ff7a12679598b362d45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6d105f734e0428fa83cf49503ad4edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "366451604dda46e3852268bdc4a3977c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef25517228f74a0cbe6232e2391069fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fde95d32621b4c68852a3effd9376b4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "references = [item[\"highlights\"] for item in test_set]\n",
    "\n",
    "print(len(baseline_summaries))\n",
    "print(len(finetuned_summaries))\n",
    "print(len(references))\n",
    "\n",
    "P_base = score(baseline_summaries, references, lang=\"en\")\n",
    "P_finetuned = score(finetuned_summaries, references, lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fe38ad02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base T5 BERTScore F1: 0.8594\n",
      "LoRA-Tuned T5 BERTScore F1: 0.8665\n"
     ]
    }
   ],
   "source": [
    "print(f\"Base T5 BERTScore F1: {P_base[2].mean().item():.4f}\")\n",
    "print(f\"LoRA-Tuned T5 BERTScore F1: {P_finetuned[2].mean().item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
